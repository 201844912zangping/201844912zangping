import os,sys
import math
from textblob import TextBlob
from textblob import Word
from nltk.corpus import stopwords

reload(sys) # Python2.5 初始化后会删除 sys.setdefaultencoding 这个方法，我们需要重新载入 
sys.setdefaultencoding('utf-8') 

#预处理，划分数据集
def preprocess(path):
    files=os.listdir(path)
    a=0
    list=[]
    label=[]
    for i in files:
        zfiles=os.listdir(path+ os.path.sep +i)
        for zfile in zfiles:
            data=open(path + os.path.sep + i + os.path.sep + zfile)
            data=data.readlines()
            data=int(str(data).lower())#统一大小写
            words=data.words#分词
            print(words)
            filteredwords=[w for w in words if(w not in stopwords.words('english'))]#去停用词
            words=filteredwords.lemmatize()
            #建字典
            dic={}
            for i in words:
                if dic.get(i):
                    dic[i]+=1
                else:
                    dic[i]=1
            for k,v in dic.items():
                    dic[k]=(1+math.log(v))#标准化tf
                    #print(k,dic[k])
            list.append(dic)
            label[a]=zfile
            a+=1
    return list,label

def Vsm(prelist): #用向量表示文件数据
    for dic in prelist:
        dic2 = {}
        m = 0
        for k,v in dic.items():
            if dic[k] >= 50:#保留词频较大的数据
                break
            m = m + 1
            dic2[k] = v
        list.append(dic2)
    return list
        
    

if __name__ == "__main__":
    path="data\traindata"
    [prelist,trainlabel]=preprocess(path)
    traindata=Vsm(prelist)
    path="data\testdata"
    [prelist,testlabel]=preprocess(path)
    testdata=Vsm(prelist)

    
